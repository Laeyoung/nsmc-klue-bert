{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7403681c",
   "metadata": {},
   "source": [
    "# NSMC Sentimental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1491792e",
   "metadata": {},
   "source": [
    "본 과정은 Ainize Workspace에서 klue/bert-base 모델을 NSMC(Naver sentiment movie corpus) 데이터 셋으로 학습하는 과정입니다.\n",
    "\n",
    "최종 목표는 학습된 모델을 통해 감정 분류(Sentimental Analysis)를 하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfad54b",
   "metadata": {},
   "source": [
    "### 라이브러리 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c5c029",
   "metadata": {},
   "source": [
    "transformers는 분류, 정보 추출, 질문 답변, 요약, 번역, 문장 생성 등을 100개 이상의 언어로 수행할 수 있는 수천개의 사전학습된 모델을 제공하는 라이브러리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a451b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.12.5 in /opt/conda/lib/python3.8/site-packages (4.12.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (4.62.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (3.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (21.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (1.19.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (6.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.0.46)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.2.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.12.5) (4.0.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.12.5) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2.0.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (8.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.12.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d12b5",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기\n",
    "본 과정에서 사용할 라이브러리들을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712a2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf119ca7",
   "metadata": {},
   "source": [
    "### Parameters 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970fcce6",
   "metadata": {},
   "source": [
    "학습에 사용될 parameters(학습/평가 데이터 경로, 에폭 등)를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e50d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'train_data_path': './nsmc/ratings_train.txt',\n",
    "    'val_data_path': './nsmc/ratings_test.txt',\n",
    "    'save_path': './model',\n",
    "    'max_epochs': 3,\n",
    "    'model_path': 'klue/bert-base',\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 5e-6,\n",
    "    'warmup_ratio': 0.0,\n",
    "    'max_seq_len': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f4fde",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808c1a9",
   "metadata": {},
   "source": [
    "우선 데이터를 살펴보겠습니다. \n",
    "\n",
    "데이터는 영화 리뷰와 리뷰에 대한 라벨로 구성되어 있습니다. 평점이 10, 9인 리뷰에 대해서는 긍정(1), 평점이 1, 2, 3, 4인 리뷰에 대해서는 부정(0)으로 라벨링되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccea3394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[150000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(args[\"train_data_path\"], sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aada41",
   "metadata": {},
   "source": [
    "다운로드 받은 nsmc 데이터로부터 학습 데이터를 만들기 위해 Pytorch Dataset을 만들어 줍니다. \n",
    "\n",
    "데이터에 NaN 값과 중복 된 값이 포함되어 있어 이를 제거하는 작업과 입력으로 들어온 문자열을 max_length까지 자르는 작업을 진행하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a337033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSMCDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length):\n",
    "        df = pd.read_csv(csv_file, sep='\\t')\n",
    "        # NaN 값 제거\n",
    "        df = df.dropna(axis=0)\n",
    "        # 중복 제거\n",
    "        df.drop_duplicates(subset=['document'], inplace=True)\n",
    "        self.input_ids = tokenizer.batch_encode_plus(\n",
    "            df['document'].to_list(),\n",
    "            padding='max_length',\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=False,\n",
    "            truncation=True,\n",
    "        )['input_ids']\n",
    "        self.labels = torch.LongTensor(df['label'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d0ef9",
   "metadata": {},
   "source": [
    "### Model 및 Tokenizer 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956319f9",
   "metadata": {},
   "source": [
    "학습에 사용할 모델과 Tokenizer 파일을 Huggingface에서 불러옵니다.\n",
    "\n",
    "모델을 불러오면 경고가 발생하는 데 이는 fine-tuning 하기 전에는 모델의 성능이 좋지 않을 것이라고 알려줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4c2107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(args['model_path'], num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args['model_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c188f",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc33765",
   "metadata": {},
   "source": [
    "모델을 학습합니다. 학습에 사용할 파라메터는 args에서 정의 하였습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32306374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, args):\n",
    "    model.train()\n",
    "    model.to('cuda')\n",
    "    global_total_step = len(train_dataloader) * args['max_epochs']\n",
    "    global_step = 0\n",
    "    optimizer = AdamW(model.parameters(), lr=args['learning_rate'], weight_decay=0.0)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0,\n",
    "                                                num_training_steps=global_total_step)\n",
    "    with tqdm(total=global_total_step, unit='step') as t:\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for epoch in range(args['max_epochs']):\n",
    "            for batch in train_dataloader:\n",
    "                global_step += 1\n",
    "                b_input_ids = batch[0].to('cuda', non_blocking=True)\n",
    "                b_labels = batch[1].to('cuda', non_blocking=True)\n",
    "                model.zero_grad(set_to_none=True)\n",
    "                outputs = model(\n",
    "                    input_ids=b_input_ids,\n",
    "                    labels=b_labels\n",
    "                )\n",
    "                loss, logits = outputs.loss, outputs.logits\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                preds = logits.detach().argmax(dim=-1).cpu().numpy()\n",
    "                out_label_ids = b_labels.detach().cpu().numpy()\n",
    "                total_correct += (preds == out_label_ids).sum()\n",
    "\n",
    "                batch_loss = loss.item() * len(b_input_ids)\n",
    "\n",
    "                total += len(b_input_ids)\n",
    "                total_loss += batch_loss\n",
    "\n",
    "                t.set_postfix(loss='{:.6f}'.format(batch_loss),\n",
    "                              accuracy='{:.2f}'.format(total_correct / total * 100))\n",
    "                t.update(1)\n",
    "                del b_input_ids\n",
    "                del outputs\n",
    "                del loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1c438",
   "metadata": {},
   "source": [
    "데이터들을 토큰화한 후, 학습에 사용할 수 있도록 구성하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8bf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = NSMCDataset(args['train_data_path'], tokenizer, args['max_seq_len'])\n",
    "train_data_loader = DataLoader(\n",
    "    dataset=train_data_set,\n",
    "    batch_size=args['batch_size'],\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064bf34",
   "metadata": {},
   "source": [
    "학습을 진행하겠습니다. 학습이 진행될 수록 정확도(accuracy)가 높아지다가 어느 정도에 수렴하는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b4e427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e9e6be76ad4c8c87d0cc250d27bd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13707 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, train_data_loader, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08289f9",
   "metadata": {},
   "source": [
    "학습이 완료된 모델을 저장하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16d735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(args['save_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66602fb",
   "metadata": {},
   "source": [
    "### Smaple Data 넣어 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54130ce9",
   "metadata": {},
   "source": [
    "학습된 모델에 Smaple Data를 넣어 학습 결과를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85edf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평점 10\n",
    "pos_text = '이방원을 다룬 드라마중 최고였다고 자부함. 진짜 이방원을 보여준 듯이 연기와 인물묘사나 주변상황이 재밌었고 스토리도 진부하지 않았음. 다시 이런드라마를 볼수 있을지~ 진짜 이런 드라마하나 또 나왔음 함.'\n",
    "# 평점 0\n",
    "neg_text = '핵노잼 후기보고 낙였네 방금보고왔는데 개실망 재미없어요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedb03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이방원을 다룬 드라마중 최고였다고 자부함. 진짜 이방원을 보여준 듯이 연기와 인물묘사나 주변상황이 재밌었고 스토리도 진부하지 않았음. 다시 이런드라마를 볼수 있을지~ 진짜 이런 드라마하나 또 나왔음 함. : 1\n",
      "핵노잼 후기보고 낙였네 방금보고왔는데 개실망 재미없어요 : 0\n"
     ]
    }
   ],
   "source": [
    "pos_input_vector = tokenizer.encode(pos_text, return_tensors='pt').to('cuda')\n",
    "pos_pred = model(input_ids=pos_input_vector, labels=None).logits.argmax(dim=-1).tolist()\n",
    "print(f'{pos_text} : {pos_pred[0]}')\n",
    "\n",
    "neg_input_vector = tokenizer.encode(neg_text, return_tensors='pt').to('cuda')\n",
    "neg_pred = model(input_ids=neg_input_vector, labels=None).logits.argmax(dim=-1).tolist()\n",
    "print(f'{neg_text} : {neg_pred[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbba4f",
   "metadata": {},
   "source": [
    "지금까지 klue/bert-base 모델을 NSMC(Naver sentiment movie corpus)데이터 셋으로 학습하는 과정을 진행해보았습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
